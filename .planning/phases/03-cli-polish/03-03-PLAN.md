---
phase: 03-cli-polish
plan: 03
type: execute
wave: 2
depends_on: ["03-01", "03-02"]
files_modified:
  - src/parallel/processor.ts
  - src/cli/index.ts
  - package.json
autonomous: true

must_haves:
  truths:
    - "User can enable parallel processing via --jobs flag"
    - "--jobs flag accepts number or 'all' keyword"
    - "Default job count is (CPU count - 1)"
    - "Tool processes multiple EPUBs simultaneously"
    - "Progress bars show parallel jobs with individual bars"
  artifacts:
    - path: "src/parallel/processor.ts"
      provides: "Parallel EPUB processing with p-limit concurrency control"
      min_lines: 80
      exports: ["processInParallel", "getJobCount"]
    - path: "src/cli/index.ts"
      provides: "CLI integration with --jobs flag"
      contains: "\\.option.*--jobs"
    - path: "package.json"
      provides: "p-limit dependency"
      contains: "p-limit"
  key_links:
    - from: "src/cli/index.ts"
      to: "src/parallel/processor.ts"
      via: "import { processInParallel, getJobCount }"
      pattern: "import.*from.*parallel"
    - from: "src/parallel/processor.ts"
      to: "p-limit"
      via: "pLimit import and usage"
      pattern: "pLimit|from 'p-limit'"
    - from: "src/parallel/processor.ts"
      to: "os.cpus()"
      via: "CPU core detection"
      pattern: "os\\.cpus\\(\\)"
    - from: "src/cli/index.ts"
      to: "commander"
      via: "--jobs flag option definition"
      pattern: "\\.option.*--jobs"
---

<objective>
Implement parallel EPUB processing with p-limit concurrency control and CPU-aware default job count.

Purpose: Speed up batch processing by utilizing multiple CPU cores. EPUB processing is I/O-bound (file reading, parsing), making it ideal for parallel processing with async operations.

Output: Working parallel processing system with --jobs flag (number or "all"), CPU-aware default ((CPU count - 1)), and individual progress bars for each parallel job.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-cli-polish/03-RESEARCH.md
@.planning/phases/03-cli-polish/03-CONTEXT.md

# Codebase context
@src/cli/index.ts
@src/errors/handler.ts
@src/cli/progress.ts
@.planning/phases/03-cli-polish/03-01-PLAN.md
@.planning/phases/03-cli-polish/03-02-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Install p-limit dependency</name>
  <files>package.json</files>
  <action>
    Install p-limit package:

    ```bash
    npm install p-limit
    ```

    Use version 6.2.0 (current stable). This package provides Promise-based concurrency control, perfect for I/O-bound EPUB processing. Don't use worker_threads - EPUB processing is I/O-bound, not CPU-bound (see RESEARCH.md Anti-Patterns).
  </action>
  <verify>Check package.json has "p-limit" in dependencies</verify>
  <done>p-limit installed and available</done>
</task>

<task type="auto">
  <name>Create parallel processing module with p-limit</name>
  <files>src/parallel/processor.ts</files>
  <action>
    Create src/parallel/processor.ts with parallel EPUB processing:

    **Requirements from RESEARCH.md:**
    - Use p-limit for concurrency control (not worker_threads)
    - CPU-aware default: (CPU count - 1) or 1
    - --jobs flag accepts: number, "all", or undefined (default)
    - Warn if --jobs > 32 (diminishing returns)
    - Individual progress bars per parallel job (using progress.ts from plan 03-01)
    - Fallback for os.cpus() returning undefined/empty

    **Code structure:**
    ```typescript
    import os from 'os';
    import pLimit from 'p-limit';
    import path from 'path';
    import { processEpubsWithErrors } from '../errors/handler.js';
    import { createBar, type Bar } from '../cli/progress.js';
    import type { MultiBar } from 'cli-progress';
    import type { EpubResult } from '../output/table.js';
    import type { TokenizerResult } from '../tokenizers/types.js';

    export interface ParallelProcessingResult {
      successful: EpubResult[];
      failed: Array<{ file: string; error: string; suggestion?: string }>;
      total: number;
      tokenCounts: Map<string, TokenizerResult[]>;
    }

    /**
     * Get job count from --jobs flag with CPU-aware default
     * @param jobsFlag - Value from --jobs flag (number, "all", or undefined)
     * @returns Number of parallel jobs to run
     */
    export function getJobCount(jobsFlag?: string): number {
      const cpus = os.cpus();
      const cpuCount = cpus?.length || 1; // Fallback for containers/CI

      if (!jobsFlag) {
        // Default: CPU count - 1 (leave one core for system)
        return Math.max(1, cpuCount - 1);
      }

      if (jobsFlag === 'all') {
        return cpuCount;
      }

      const parsed = parseInt(jobsFlag, 10);
      if (isNaN(parsed) || parsed <= 0) {
        throw new Error(`--jobs must be a positive number or "all", got "${jobsFlag}"`);
      }

      // Warn if >32 jobs (diminishing returns)
      if (parsed > 32) {
        console.warn(`Warning: --jobs=${parsed} is unusually high. Consider using "all" (${cpuCount} cores) or a lower value.`);
      }

      return parsed;
    }

    /**
     * Process EPUB files in parallel with progress tracking
     * @param filePaths - Array of EPUB file paths
     * @param jobCount - Number of parallel jobs to run
     * @param multibar - MultiBar instance for progress display
     * @param verbose - Enable verbose output
     * @param outputDir - Output directory for error logs
     * @param tokenizerNames - Tokenizer names to use
     * @param maxMb - Maximum EPUB size in MB
     * @returns Promise resolving to processing results
     */
    export async function processInParallel(
      filePaths: string[],
      jobCount: number,
      multibar: MultiBar,
      verbose: boolean = false,
      outputDir: string = './results',
      tokenizerNames: string[] = ['gpt4'],
      maxMb: number = 500
    ): Promise<ParallelProcessingResult> {
      // Create concurrency limiter
      const limit = pLimit(jobCount);

      // Aggregate results
      const allSuccessful: EpubResult[] = [];
      const allFailed: Array<{ file: string; error: string; suggestion?: string }> = [];
      const allTokenCounts = new Map<string, TokenizerResult[]>();

      // Create tasks for each file
      const tasks = filePaths.map((filePath) => {
        return limit(async () => {
          const filename = path.basename(filePath);

          // Create individual progress bar for this job
          const bar = createBar(multibar, filename);

          try {
            // Process single file
            const result = await processEpubsWithErrors(
              [filePath],
              verbose,
              outputDir,
              tokenizerNames,
              maxMb
            );

            // Update progress to 100% (complete)
            bar.update(100);

            return result;
          } catch (error) {
            // FATAL error - bar stays at current progress
            throw error;
          }
        });
      });

      // Wait for all tasks to complete
      const results = await Promise.all(tasks);

      // Aggregate results from all tasks
      for (const result of results) {
        allSuccessful.push(...result.successful);
        allFailed.push(...result.failed);
        // Merge tokenCounts maps
        for (const [filename, counts] of result.tokenCounts.entries()) {
          allTokenCounts.set(filename, counts);
        }
      }

      return {
        successful: allSuccessful,
        failed: allFailed,
        total: filePaths.length,
        tokenCounts: allTokenCounts,
      };
    }
    ```

    **Key implementation details:**
    - Use `pLimit(jobCount)` to create concurrency limiter
    - Each task: `limit(async () => { ... })` wraps async operation
    - Dynamic bar creation: `createBar(multibar, filename)` within each task
    - Progress updates: `bar.update(100)` on completion
    - Aggregate results: Promise.all() + merge arrays/maps
    - Fallback for os.cpus(): `cpus?.length || 1`

    **Why not worker_threads?** EPUB processing is I/O-bound (file reading, parsing), not CPU-bound. p-limit is simpler and more appropriate (see RESEARCH.md).
  </action>
  <verify>Check that:
  - src/parallel/processor.ts exists
  - Exports getJobCount function with CPU-aware default
  - Exports processInParallel function with p-limit usage
  - getJobCount handles: undefined (default), "all", number, invalid values
  - getJobCount warns if >32 jobs
  - getJobCount has fallback for os.cpus() returning undefined
  - processInParallel creates bars dynamically within tasks
  - processInParallel aggregates results from all tasks
  </verify>
  <done>Parallel processing module created</done>
</task>

<task type="auto">
  <name>Integrate parallel processing into CLI</name>
  <files>src/cli/index.ts</files>
  <action>
    Modify src/cli/index.ts to add --jobs flag and integrate parallel processing:

    **Changes:**

    1. Add imports:
    ```typescript
    import { processInParallel, getJobCount } from '../parallel/processor.js';
    import { createProgressBars, stopAll } from '../cli/progress.js';
    ```

    2. Add --jobs flag option:
    ```typescript
    program
      // ... existing options ...
      .option('-j, --jobs <count>', 'Number of parallel jobs (default: CPU count - 1, use "all" for max cores)')
      .action((paths, options) => {
        // ... existing code ...

        // Parse jobs flag
        let jobs: number | undefined;
        if (options.jobs) {
          try {
            jobs = getJobCount(options.jobs);
          } catch (error) {
            console.error(error instanceof Error ? error.message : error);
            process.exit(1);
          }
        }

        // Pass jobs to processEpubs
        processEpubs(inputPaths, { ...options, jobs })
          .catch((error) => {
            console.error('Fatal error:', error);
            process.exit(1);
          });
      });
    ```

    3. Update processEpubs function to use parallel processing:
    ```typescript
    async function processEpubs(inputPaths: string[], options: any): Promise<void> {
      // ... existing file discovery code ...

      // Determine job count
      const jobs = options.jobs ? getJobCount(options.jobs) : getJobCount();

      // Display job count if verbose
      if (options.verbose) {
        console.log(`Using ${jobs} parallel job(s)`);
      }

      // Create MultiBar for progress display
      const multibar = createProgressBars();

      let result;

      // Process EPUBs (parallel or sequential)
      if (jobs > 1) {
        // Parallel processing
        result = await processInParallel(
          allFiles,
          jobs,
          multibar,
          options.verbose,
          outputDir,
          tokenizers,
          maxMb
        );
      } else {
        // Sequential processing (existing behavior)
        // ... keep existing loop from plan 03-01 ...
        result = await processEpubsWithErrors(...);
      }

      // Stop all progress bars
      stopAll(multibar);

      // ... rest of function (displayResults, writeFiles, summary) ...
    }
    ```

    **Important:** Keep sequential processing fallback for jobs=1 or single file. This preserves existing behavior and allows easy debugging.

    **Progress bar integration:**
    - Parallel: Individual bars created per job (by processInParallel)
    - Sequential: Reuse code from plan 03-01 (create bars upfront, update in loop)
  </action>
  <verify>Check that:
  - --jobs flag added to commander options
  - getJobCount called with options.jobs
  - processInParallel imported and used for jobs > 1
  - Sequential processing used for jobs = 1
  - MultiBar created before processing, stopped after
  - Verbose mode shows job count
  </verify>
  <done>--jobs flag enables parallel processing</done>
</task>

</tasks>

<verification>
1. Test parallel processing with multiple EPUB files
2. Verify CPU detection and default job count
3. Test --jobs flag with number and "all" keyword
4. Verify individual progress bars for parallel jobs
5. Verify speedup with parallel processing

Test commands:
```bash
# Test default (CPU count - 1)
epub-counter ./epubs/

# Test specific job count
epub-counter ./epubs/ --jobs 4

# Test "all" keyword
epub-counter ./epubs/ --jobs all

# Test with verbose (should show job count)
epub-counter ./epubs/ --jobs 2 -v

# Test sequential fallback (--jobs 1)
epub-counter ./epubs/ --jobs 1
```

Expected output:
- Default: Uses (CPU count - 1) parallel jobs
- --jobs 4: Uses 4 parallel jobs
- --jobs all: Uses all CPU cores
- Verbose: Shows "Using N parallel job(s)"
- Progress: Individual bars for each parallel job
- Speedup: Parallel processing faster than sequential (for multiple files)
</verification>

<success_criteria>
- --jobs flag accepts number or "all" keyword
- Default job count is (CPU count - 1)
- Parallel processing speeds up batch operations
- Individual progress bars show for each parallel job
- Sequential processing preserved for --jobs 1
- Warning shown if --jobs > 32
</success_criteria>

<output>
After completion, create `.planning/phases/03-cli-polish/03-03-SUMMARY.md`
</output>
