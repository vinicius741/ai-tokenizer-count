---
phase: 02-tokenization-engine
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - package-lock.json
  - src/tokenizers/types.ts
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Tokenizer libraries are installed and available in node_modules"
    - "Tokenizer interface exists with countTokens method"
    - "TokenizerResult type defines the structure for token count results"
    - "TokenizerFactory can create tokenizers by name"
  artifacts:
    - path: "package.json"
      contains: "js-tiktoken"
    - path: "package.json"
      contains: "@anthropic-ai/tokenizer"
    - path: "package.json"
      contains: "@huggingface/transformers"
    - path: "src/tokenizers/types.ts"
      provides: "Tokenizer interface and TokenizerFactory"
      exports: ["Tokenizer", "TokenizerResult", "TokenizerFactory"]
      min_lines: 30
  key_links:
    - from: "src/tokenizers/types.ts"
      to: "package.json"
      via: "import statements will use installed packages"
      pattern: "import.*from.*(js-tiktoken|@anthropic-ai/tokenizer|@huggingface/transformers)"
---

<objective>
Install tokenizer library dependencies and create the core abstraction layer for tokenization.

Purpose: Establish the foundation for multi-model tokenization by installing the three required tokenizer libraries (js-tiktoken for GPT-4, @anthropic-ai/tokenizer for Claude, @huggingface/transformers for custom models) and defining the unified interface that all tokenizers will implement.

Output: Updated package.json with new dependencies, and src/tokenizers/types.ts with Tokenizer interface and factory pattern.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Codebase context
@src/output/json.ts
@src/errors/handler.ts
@src/cli/index.ts

# Research findings
@.planning/phases/02-tokenization-engine/02-RESEARCH.md
@.planning/phases/02-tokenization-engine/02-CONTEXT.md
</context>

<tasks>

<task type="auto">
  <name>Install tokenizer dependencies</name>
  <files>package.json, package-lock.json</files>
  <action>
    Install the three tokenizer libraries identified in research:

    1. Run: npm install js-tiktoken @anthropic-ai/tokenizer @huggingface/transformers
    2. Verify package.json contains all three dependencies
    3. Use caret (^) version ranges for latest compatible versions

    These are the standard stack per RESEARCH.md:
    - js-tiktoken: Pure JS port of OpenAI's tiktoken for GPT-4
    - @anthropic-ai/tokenizer: Official Anthropic package for Claude
    - @huggingface/transformers: Official Hugging Face Transformers.js for arbitrary models
  </action>
  <verify>grep -E "(js-tiktoken|@anthropic-ai/tokenizer|@huggingface/transformers)" package.json returns three matching lines</verify>
  <done>All three tokenizer packages are installed and listed in package.json dependencies</done>
</task>

<task type="auto">
  <name>Create tokenizer types and interfaces</name>
  <files>src/tokenizers/types.ts</files>
  <action>
    Create src/tokenizers/types.ts with:

    1. **Tokenizer interface** - Abstraction for all tokenizer implementations:
       - name: string (e.g., "gpt4", "claude", "bert-base-uncased")
       - countTokens(text: string): number | Promise<number>

    2. **TokenizerResult interface** - Return type for tokenization:
       - name: string
       - count: number

    3. **TokenizerFactory** - Factory function to create tokenizers by name:
       - createTokenizer(name: string): Tokenizer
       - Handles preset names: "gpt4", "claude"
       - Handles Hugging Face model names (anything else)
       - Throws error for invalid names

    Follow existing codebase patterns:
    - Use ES6 modules (import/export)
    - Use JSDoc comments like in src/epub/parser.ts
    - Export interfaces and functions separately

    Per CONTEXT.md decision: Use short preset names (gpt4, claude) not cl100k_base.
  </action>
  <verify>grep -E "(interface Tokenizer|interface TokenizerResult|createTokenizer)" src/tokenizers/types.ts returns expected exports</verify>
  <done>src/tokenizers/types.ts exists with Tokenizer interface, TokenizerResult interface, and TokenizerFactory export</done>
</task>

</tasks>

<verification>
After completion, verify:
- [ ] npm install completed without errors
- [ ] package.json contains js-tiktoken, @anthropic-ai/tokenizer, @huggingface/transformers
- [ ] src/tokenizers/types.ts exists and compiles without errors (run npm run build)
- [ ] Tokenizer interface has name property and countTokens method
- [ ] TokenizerFactory handles gpt4, claude, and arbitrary HF model names
</verification>

<success_criteria>
1. TypeScript compilation succeeds (npm run build)
2. src/tokenizers/types.ts exports Tokenizer, TokenizerResult, createTokenizer
3. TokenizerFactory can be imported and create() returns valid Tokenizer instances
</success_criteria>

<output>
After completion, create `.planning/phases/02-tokenization-engine/02-01-SUMMARY.md`
</output>
